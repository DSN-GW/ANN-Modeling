{
  "model_performance": {
    "feature_count": 51,
    "top_features": [
      [
        "FSR",
        0.21732522547245026
      ],
      [
        "BIS",
        0.16316881775856018
      ],
      [
        "sweets_mentioned",
        0.03204217180609703
      ],
      [
        "positive_attributes",
        0.031011860817670822
      ],
      [
        "shortness_score",
        0.025772010907530785
      ],
      [
        "char_count",
        0.024310866370797157
      ],
      [
        "LPA_Profile_grand_mean",
        0.02339140512049198
      ],
      [
        "word_count",
        0.02210916392505169
      ],
      [
        "toys, gadgets and games_sentiment",
        0.020724233239889145
      ],
      [
        "connector_ratio",
        0.017187342047691345
      ],
      [
        "verb_ratio",
        0.016931835561990738
      ],
      [
        "flesch_reading_ease",
        0.01686040125787258
      ],
      [
        "sports_sentiment",
        0.016545962542295456
      ],
      [
        "positive_word_count",
        0.016540218144655228
      ],
      [
        "Fruits and vegetables_sentiment",
        0.016534574329853058
      ]
    ]
  },
  "characteristic_analysis": {
    "personality inference": {
      "total_importance": 0.021574989892542362,
      "features": [
        "personality inference_mentioned",
        "personality inference_sentiment"
      ],
      "feature_count": 2
    },
    "sweets": {
      "total_importance": 0.04204985871911049,
      "features": [
        "sweets_mentioned",
        "sweets_sentiment"
      ],
      "feature_count": 2
    },
    "Fruits and vegetables": {
      "total_importance": 0.031070338562130928,
      "features": [
        "Fruits and vegetables_mentioned",
        "Fruits and vegetables_sentiment"
      ],
      "feature_count": 2
    },
    "healthy savory food": {
      "total_importance": 0.01648458046838641,
      "features": [
        "healthy savory food_mentioned",
        "healthy savory food_sentiment"
      ],
      "feature_count": 2
    },
    "food": {
      "total_importance": 0.02433801908046007,
      "features": [
        "food_mentioned",
        "food_sentiment"
      ],
      "feature_count": 2
    },
    "cosmetics": {
      "total_importance": 0.0,
      "features": [
        "cosmetics_mentioned",
        "cosmetics_sentiment"
      ],
      "feature_count": 2
    },
    "fashion": {
      "total_importance": 0.0,
      "features": [
        "fashion_mentioned",
        "fashion_sentiment"
      ],
      "feature_count": 2
    },
    "toys, gadgets and games": {
      "total_importance": 0.030636195093393326,
      "features": [
        "toys, gadgets and games_mentioned",
        "toys, gadgets and games_sentiment"
      ],
      "feature_count": 2
    },
    "sports": {
      "total_importance": 0.024280680809170008,
      "features": [
        "sports_mentioned",
        "sports_sentiment"
      ],
      "feature_count": 2
    },
    "music": {
      "total_importance": 0.0067575774155557156,
      "features": [
        "music_mentioned",
        "music_sentiment"
      ],
      "feature_count": 2
    },
    "arts and crafts": {
      "total_importance": 0.021634437143802643,
      "features": [
        "arts and crafts_mentioned",
        "arts and crafts_sentiment"
      ],
      "feature_count": 2
    }
  },
  "class_patterns": {
    "td_patterns": {
      "personality inference": {
        "personality inference_mentioned": 0.469910371318822,
        "personality inference_sentiment": 0.040973111395646605
      },
      "sweets": {
        "sweets_mentioned": 0.22407170294494239,
        "sweets_sentiment": 0.058898847631242
      },
      "Fruits and vegetables": {
        "Fruits and vegetables_mentioned": 0.33034571062740076,
        "Fruits and vegetables_sentiment": 0.19334186939820744
      },
      "healthy savory food": {
        "healthy savory food_mentioned": 0.1792573623559539,
        "healthy savory food_sentiment": 0.117797695262484
      },
      "food": {
        "food_mentioned": 0.6056338028169014,
        "food_sentiment": 0.26632522407170295
      },
      "cosmetics": {
        "cosmetics_mentioned": 0.0,
        "cosmetics_sentiment": 0.0
      },
      "fashion": {
        "fashion_mentioned": 0.016645326504481434,
        "fashion_sentiment": 0.002560819462227913
      },
      "toys, gadgets and games": {
        "toys, gadgets and games_mentioned": 0.18437900128040974,
        "toys, gadgets and games_sentiment": 0.04225352112676056
      },
      "sports": {
        "sports_mentioned": 0.3444302176696543,
        "sports_sentiment": 0.028169014084507043
      },
      "music": {
        "music_mentioned": 0.2586427656850192,
        "music_sentiment": 0.1677336747759283
      },
      "arts and crafts": {
        "arts and crafts_mentioned": 0.2087067861715749,
        "arts and crafts_sentiment": 0.03969270166453265
      }
    },
    "asd_patterns": {
      "personality inference": {
        "personality inference_mentioned": 0.4318862275449102,
        "personality inference_sentiment": 0.04640718562874251
      },
      "sweets": {
        "sweets_mentioned": 0.16841317365269462,
        "sweets_sentiment": 0.0561377245508982
      },
      "Fruits and vegetables": {
        "Fruits and vegetables_mentioned": 0.23877245508982037,
        "Fruits and vegetables_sentiment": 0.14221556886227546
      },
      "healthy savory food": {
        "healthy savory food_mentioned": 0.13697604790419163,
        "healthy savory food_sentiment": 0.07709580838323353
      },
      "food": {
        "food_mentioned": 0.5082335329341318,
        "food_sentiment": 0.2537425149700599
      },
      "cosmetics": {
        "cosmetics_mentioned": 0.0007485029940119761,
        "cosmetics_sentiment": 0.0007485029940119761
      },
      "fashion": {
        "fashion_mentioned": 0.010479041916167664,
        "fashion_sentiment": 0.004491017964071856
      },
      "toys, gadgets and games": {
        "toys, gadgets and games_mentioned": 0.1534431137724551,
        "toys, gadgets and games_sentiment": 0.050149700598802395
      },
      "sports": {
        "sports_mentioned": 0.25523952095808383,
        "sports_sentiment": 0.05389221556886228
      },
      "music": {
        "music_mentioned": 0.2148203592814371,
        "music_sentiment": 0.15568862275449102
      },
      "arts and crafts": {
        "arts and crafts_mentioned": 0.1407185628742515,
        "arts and crafts_sentiment": 0.0531437125748503
      }
    }
  },
  "characteristic_summary": {
    "personality inference": {
      "importance_score": 0.021574989892542362,
      "feature_count": 2,
      "rank": 7
    },
    "sweets": {
      "importance_score": 0.04204985871911049,
      "feature_count": 2,
      "rank": 1
    },
    "Fruits and vegetables": {
      "importance_score": 0.031070338562130928,
      "feature_count": 2,
      "rank": 2
    },
    "healthy savory food": {
      "importance_score": 0.01648458046838641,
      "feature_count": 2,
      "rank": 8
    },
    "food": {
      "importance_score": 0.02433801908046007,
      "feature_count": 2,
      "rank": 4
    },
    "cosmetics": {
      "importance_score": 0.0,
      "feature_count": 2,
      "rank": 10
    },
    "fashion": {
      "importance_score": 0.0,
      "feature_count": 2,
      "rank": 11
    },
    "toys, gadgets and games": {
      "importance_score": 0.030636195093393326,
      "feature_count": 2,
      "rank": 3
    },
    "sports": {
      "importance_score": 0.024280680809170008,
      "feature_count": 2,
      "rank": 5
    },
    "music": {
      "importance_score": 0.0067575774155557156,
      "feature_count": 2,
      "rank": 9
    },
    "arts and crafts": {
      "importance_score": 0.021634437143802643,
      "feature_count": 2,
      "rank": 6
    }
  },
  "prediction_explanations": [
    {
      "sample_id": 582,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.8227577209472656,
        "BIS": 1.263015866279602,
        "char_count": -0.10510578751564026,
        "LPA_Profile_grand_mean": 0.08489803224802017,
        "avg_sentence_length": -0.07949338853359222,
        "punctuation_ratio": -0.07325677573680878,
        "adj_ratio": 0.06684456020593643,
        "flesch_reading_ease": 0.065665602684021,
        "avg_word_length": -0.06524111330509186,
        "word_count": -0.06507905572652817
      }
    },
    {
      "sample_id": 1433,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.2890708446502686,
        "FSR": 1.9310765266418457,
        "LPA_Profile_grand_mean": 0.09520772099494934,
        "avg_word_length": -0.07152670621871948,
        "char_count": -0.05187181755900383,
        "sentiment_polarity": -0.04455992951989174,
        "punctuation_ratio": -0.042455416172742844,
        "cohesiveness_score": 0.036076996475458145,
        "shortness_score": -0.034340471029281616,
        "positive_word_ratio": 0.033522237092256546
      }
    },
    {
      "sample_id": 815,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.275482654571533,
        "FSR": 1.8242276906967163,
        "LPA_Profile_grand_mean": 0.17625011503696442,
        "char_count": 0.11158885806798935,
        "avg_word_length": -0.07896018773317337,
        "sentiment_subjectivity": -0.0675252228975296,
        "adj_ratio": 0.049605593085289,
        "avg_sentence_length": 0.043004442006349564,
        "word_count": 0.04037635773420334,
        "punctuation_ratio": 0.03982056677341461
      }
    },
    {
      "sample_id": 193,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -2.0152530670166016,
        "BIS": -1.9806609153747559,
        "LPA_Profile_grand_mean": -0.08838768303394318,
        "avg_word_length": -0.07104703783988953,
        "adj_ratio": 0.057420823723077774,
        "char_count": -0.05512780323624611,
        "verb_ratio": 0.0542217493057251,
        "flesch_reading_ease": -0.03905768319964409,
        "shortness_score": -0.031129850074648857,
        "sentiment_polarity": -0.029795095324516296
      }
    },
    {
      "sample_id": 1187,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.68265700340271,
        "BIS": -1.5218336582183838,
        "char_count": 0.20073872804641724,
        "LPA_Profile_grand_mean": 0.17514236271381378,
        "adj_ratio": -0.1390816867351532,
        "flesch_reading_ease": 0.10495542734861374,
        "avg_PE": -0.07882870733737946,
        "avg_word_length": 0.06488224118947983,
        "word_count": 0.06294731795787811,
        "flesch_kincaid_grade": -0.05008852481842041
      }
    },
    {
      "sample_id": 1923,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.331718683242798,
        "FSR": 1.8988261222839355,
        "LPA_Profile_grand_mean": 0.14197984337806702,
        "adj_ratio": 0.05079418793320656,
        "avg_PE": -0.0428498312830925,
        "word_count": 0.0397990383207798,
        "punctuation_ratio": 0.030656905844807625,
        "shortness_score": 0.027825139462947845,
        "positive_word_ratio": 0.026110703125596046,
        "flesch_reading_ease": -0.02491392195224762
      }
    },
    {
      "sample_id": 1304,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3153436183929443,
        "FSR": 1.8553944826126099,
        "LPA_Profile_grand_mean": -0.07658091932535172,
        "avg_PE": -0.055861104279756546,
        "verb_ratio": 0.055441997945308685,
        "avg_sentence_length": -0.052166782319545746,
        "Fruits and vegetables_sentiment": -0.04088468477129936,
        "punctuation_ratio": -0.030269332230091095,
        "positive_word_ratio": 0.029779698699712753,
        "avg_word_length": 0.028664086014032364
      }
    },
    {
      "sample_id": 2062,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": -0.9743143320083618,
        "BIS": 0.28861647844314575,
        "LPA_Profile_grand_mean": 0.1860564798116684,
        "char_count": 0.12900294363498688,
        "avg_word_length": -0.12305395305156708,
        "avg_sentence_length": 0.07366862893104553,
        "positive_word_ratio": 0.07233904302120209,
        "flesch_reading_ease": -0.06956057995557785,
        "adj_ratio": 0.0649775043129921,
        "avg_PE": -0.05705328658223152
      }
    },
    {
      "sample_id": 1658,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.1999597549438477,
        "FSR": 1.7109345197677612,
        "LPA_Profile_grand_mean": -0.09118752926588058,
        "char_count": 0.08428832143545151,
        "avg_PE": -0.07097707688808441,
        "sentiment_polarity": 0.06377112120389938,
        "adj_ratio": 0.04448625445365906,
        "avg_sentence_length": 0.036122579127550125,
        "connector_ratio": 0.03377366065979004,
        "punctuation_ratio": 0.027642028406262398
      }
    },
    {
      "sample_id": 342,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.2520534992218018,
        "FSR": 1.9622303247451782,
        "LPA_Profile_grand_mean": -0.09299390763044357,
        "avg_word_length": 0.07607319951057434,
        "Fruits and vegetables_sentiment": -0.04540015384554863,
        "adj_ratio": 0.03573397174477577,
        "positive_word_count": 0.02928757108747959,
        "punctuation_ratio": -0.025010354816913605,
        "avg_sentence_length": 0.02455826662480831,
        "flesch_reading_ease": -0.021759331226348877
      }
    },
    {
      "sample_id": 1648,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.2929723262786865,
        "FSR": 1.769590139389038,
        "adj_ratio": 0.09719064086675644,
        "sentiment_polarity": 0.08384775370359421,
        "avg_word_length": 0.06647595018148422,
        "LPA_Profile_grand_mean": -0.055342625826597214,
        "connector_ratio": 0.03931432217359543,
        "avg_sentence_length": -0.03122727759182453,
        "punctuation_ratio": 0.030128849670290947,
        "char_count": -0.026668867096304893
      }
    },
    {
      "sample_id": 1666,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -2.0865540504455566,
        "FSR": -2.003584861755371,
        "avg_PE": 0.3617219924926758,
        "LPA_Profile_grand_mean": -0.08565224707126617,
        "adj_ratio": 0.07375919073820114,
        "avg_word_length": -0.06137944757938385,
        "negative_word_ratio": -0.05520786717534065,
        "avg_sentence_length": -0.04554435983300209,
        "flesch_reading_ease": -0.039911966770887375,
        "word_count": -0.03466622158885002
      }
    },
    {
      "sample_id": 1454,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -1.225724220275879,
        "FSR": -0.7992599606513977,
        "adj_ratio": 0.14825305342674255,
        "avg_word_length": 0.08100929111242294,
        "avg_sentence_length": -0.07601726800203323,
        "LPA_Profile_grand_mean": -0.05882251635193825,
        "word_count": -0.05425697937607765,
        "negative_word_ratio": -0.05375727266073227,
        "adv_ratio": 0.04218843951821327,
        "positive_word_count": -0.03851495310664177
      }
    },
    {
      "sample_id": 344,
      "true_label": 1,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.723336935043335,
        "BIS": -0.6355020999908447,
        "avg_PE": 0.2879134714603424,
        "LPA_Profile_grand_mean": 0.23558180034160614,
        "adj_ratio": -0.1826496571302414,
        "avg_sentence_length": 0.0540580153465271,
        "avg_word_length": -0.04632463678717613,
        "sentiment_subjectivity": 0.032157596200704575,
        "verb_ratio": -0.027164801955223083,
        "positive_word_ratio": 0.02119804173707962
      }
    },
    {
      "sample_id": 913,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -0.8831770420074463,
        "BIS": -0.7651169300079346,
        "avg_PE": 0.18828991055488586,
        "char_count": 0.12132135033607483,
        "LPA_Profile_grand_mean": 0.11784613132476807,
        "avg_sentence_length": 0.07419118285179138,
        "adj_ratio": 0.06837709993124008,
        "avg_word_length": -0.06180219724774361,
        "sentiment_polarity": -0.05928032845258713,
        "sentiment_subjectivity": -0.05036941170692444
      }
    },
    {
      "sample_id": 452,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.947279691696167,
        "BIS": -1.7960950136184692,
        "LPA_Profile_grand_mean": 0.13056878745555878,
        "char_count": -0.10740453749895096,
        "avg_word_length": 0.09335377812385559,
        "positive_word_ratio": -0.08991717547178268,
        "adj_ratio": 0.06283733248710632,
        "shortness_score": -0.05747426301240921,
        "sentiment_polarity": -0.05637631565332413,
        "connector_ratio": -0.051720358431339264
      }
    },
    {
      "sample_id": 296,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": -1.0808472633361816,
        "BIS": 0.5712589025497437,
        "LPA_Profile_grand_mean": 0.23892101645469666,
        "char_count": 0.1639280468225479,
        "verb_ratio": 0.11687849462032318,
        "avg_sentence_length": 0.0855456292629242,
        "Fruits and vegetables_sentiment": -0.08122526109218597,
        "avg_word_length": 0.06177742779254913,
        "positive_word_count": 0.05442884564399719,
        "word_count": 0.04366416484117508
      }
    },
    {
      "sample_id": 1153,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.864932656288147,
        "BIS": 1.8319331407546997,
        "LPA_Profile_grand_mean": -0.1170424371957779,
        "avg_word_length": -0.10256309807300568,
        "avg_PE": -0.061334993690252304,
        "adj_ratio": 0.054440371692180634,
        "positive_word_ratio": 0.045496925711631775,
        "punctuation_ratio": 0.042155466973781586,
        "sentiment_subjectivity": 0.03266766667366028,
        "flesch_kincaid_grade": -0.031007038429379463
      }
    },
    {
      "sample_id": 1669,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.9675567150115967,
        "BIS": 1.2379543781280518,
        "avg_word_length": 0.09149697422981262,
        "adj_ratio": 0.08614879101514816,
        "cohesiveness_score": 0.08511781692504883,
        "LPA_Profile_grand_mean": -0.06482736766338348,
        "avg_sentence_length": -0.06256452202796936,
        "flesch_reading_ease": 0.05317067727446556,
        "avg_PE": -0.051975712180137634,
        "punctuation_ratio": 0.04688721522688866
      }
    },
    {
      "sample_id": 1740,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": -0.24998697638511658,
        "avg_word_length": 0.20205436646938324,
        "LPA_Profile_grand_mean": -0.14751167595386505,
        "positive_word_ratio": -0.12505096197128296,
        "flesch_reading_ease": -0.12332919985055923,
        "BIS": 0.09522978216409683,
        "verb_ratio": -0.08059748262166977,
        "adj_ratio": 0.07467466592788696,
        "positive_word_count": 0.06642015278339386,
        "avg_PE": 0.06561233103275299
      }
    },
    {
      "sample_id": 897,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 0.7758634090423584,
        "FSR": -0.36407774686813354,
        "flesch_reading_ease": 0.24310719966888428,
        "avg_word_length": -0.14013607800006866,
        "positive_word_ratio": 0.09987861663103104,
        "LPA_Profile_grand_mean": -0.09367398917675018,
        "lexical_diversity": 0.07303880155086517,
        "verb_ratio": 0.07012760639190674,
        "adj_ratio": 0.06615304946899414,
        "cohesiveness_score": 0.06441731005907059
      }
    },
    {
      "sample_id": 1583,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": -0.28443968296051025,
        "LPA_Profile_grand_mean": 0.22928692400455475,
        "flesch_reading_ease": 0.22619524598121643,
        "FSR": -0.21377207338809967,
        "avg_PE": -0.09702247381210327,
        "avg_word_length": -0.08669599890708923,
        "cohesiveness_score": 0.06863860785961151,
        "adj_ratio": 0.06433415412902832,
        "avg_sentence_length": 0.06118093803524971,
        "positive_word_ratio": 0.055320631712675095
      }
    },
    {
      "sample_id": 914,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.9636958837509155,
        "BIS": -0.5670138597488403,
        "char_count": -0.17583881318569183,
        "LPA_Profile_grand_mean": -0.158695787191391,
        "word_count": -0.09244383126497269,
        "Fruits and vegetables_sentiment": -0.07922534644603729,
        "flesch_reading_ease": 0.07093056291341782,
        "avg_word_length": -0.06717280298471451,
        "adj_ratio": 0.06210841238498688,
        "shortness_score": -0.05246661603450775
      }
    },
    {
      "sample_id": 1193,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3957629203796387,
        "FSR": 2.0177059173583984,
        "LPA_Profile_grand_mean": 0.19385455548763275,
        "adj_ratio": -0.1222296804189682,
        "avg_word_length": -0.04393191635608673,
        "avg_sentence_length": 0.027643166482448578,
        "sentiment_subjectivity": 0.02728848159313202,
        "flesch_reading_ease": -0.026684299111366272,
        "punctuation_ratio": 0.026495840400457382,
        "sentiment_polarity": -0.02453061193227768
      }
    },
    {
      "sample_id": 270,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.8413846492767334,
        "BIS": 1.3386895656585693,
        "avg_word_length": 0.13240642845630646,
        "char_count": 0.11631999909877777,
        "LPA_Profile_grand_mean": -0.10213008522987366,
        "verb_ratio": 0.057771243155002594,
        "Fruits and vegetables_sentiment": -0.056648362427949905,
        "avg_sentence_length": 0.052182406187057495,
        "positive_word_count": 0.050137363374233246,
        "flesch_reading_ease": 0.048447199165821075
      }
    },
    {
      "sample_id": 583,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.358931064605713,
        "FSR": 1.9479566812515259,
        "LPA_Profile_grand_mean": 0.15168271958827972,
        "avg_word_length": 0.08727635443210602,
        "positive_word_ratio": -0.07112490385770798,
        "adj_ratio": 0.041264332830905914,
        "char_count": 0.03924522548913956,
        "punctuation_ratio": 0.03229638561606407,
        "arts and crafts_mentioned": -0.02982720546424389,
        "avg_sentence_length": 0.028295932337641716
      }
    },
    {
      "sample_id": 286,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.9153828620910645,
        "BIS": 1.910154104232788,
        "adj_ratio": -0.14487110078334808,
        "LPA_Profile_grand_mean": -0.0968896746635437,
        "avg_word_length": -0.08520913124084473,
        "punctuation_ratio": -0.07256965339183807,
        "char_count": -0.04814948886632919,
        "positive_word_ratio": 0.026763034984469414,
        "verb_ratio": 0.025482531636953354,
        "flesch_reading_ease": -0.02290714904665947
      }
    },
    {
      "sample_id": 381,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 1.880228877067566,
        "FSR": 1.815407633781433,
        "adj_ratio": -0.20244945585727692,
        "LPA_Profile_grand_mean": 0.16507944464683533,
        "avg_PE": 0.09435006231069565,
        "positive_word_ratio": -0.07617931067943573,
        "avg_word_length": 0.06142033264040947,
        "avg_sentence_length": 0.036799442023038864,
        "punctuation_ratio": 0.029467836022377014,
        "word_count": 0.02580542489886284
      }
    },
    {
      "sample_id": 601,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.360595226287842,
        "FSR": 1.795128583908081,
        "LPA_Profile_grand_mean": -0.1156928613781929,
        "avg_word_length": -0.09666616469621658,
        "punctuation_ratio": -0.09658245742321014,
        "positive_word_ratio": -0.08856073021888733,
        "avg_PE": -0.05505527928471565,
        "char_count": 0.047297555953264236,
        "verb_ratio": -0.03656778484582901,
        "flesch_kincaid_grade": -0.03624553978443146
      }
    },
    {
      "sample_id": 1477,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.9758377075195312,
        "BIS": 1.3323205709457397,
        "avg_word_length": 0.11585598438978195,
        "char_count": -0.0778321847319603,
        "LPA_Profile_grand_mean": -0.071265809237957,
        "positive_word_count": 0.05623737722635269,
        "positive_word_ratio": 0.05523504316806793,
        "adj_ratio": -0.04985297843813896,
        "verb_ratio": 0.04864340275526047,
        "word_count": -0.04779008403420448
      }
    },
    {
      "sample_id": 1100,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.7225083112716675,
        "BIS": 0.19591419398784637,
        "positive_word_ratio": 0.10904419422149658,
        "char_count": 0.10825207829475403,
        "LPA_Profile_grand_mean": -0.1051032692193985,
        "flesch_reading_ease": 0.0882171168923378,
        "positive_word_count": 0.063907690346241,
        "verb_ratio": 0.0625741183757782,
        "sentiment_subjectivity": -0.059407856315374374,
        "adj_ratio": 0.05143553391098976
      }
    },
    {
      "sample_id": 1429,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.8111954927444458,
        "BIS": -1.5328872203826904,
        "char_count": 0.18420186638832092,
        "avg_PE": 0.18344376981258392,
        "noun_ratio": 0.11132939159870148,
        "LPA_Profile_grand_mean": -0.08986429870128632,
        "flesch_kincaid_grade": -0.05064960941672325,
        "avg_word_length": 0.03929011896252632,
        "flesch_reading_ease": 0.038252610713243484,
        "adj_ratio": 0.03684942424297333
      }
    },
    {
      "sample_id": 1614,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.047766089439392,
        "BIS": 0.14795023202896118,
        "LPA_Profile_grand_mean": -0.11517579108476639,
        "adj_ratio": -0.09956584870815277,
        "sentiment_polarity": -0.09346836060285568,
        "verb_ratio": -0.09211954474449158,
        "avg_word_length": -0.0822315663099289,
        "flesch_reading_ease": -0.07031559944152832,
        "positive_word_ratio": 0.03866278752684593,
        "positive_word_count": 0.03526470065116882
      }
    },
    {
      "sample_id": 2096,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3219239711761475,
        "FSR": 1.868643879890442,
        "noun_ratio": 0.0830853134393692,
        "sentiment_subjectivity": -0.06493867933750153,
        "LPA_Profile_grand_mean": -0.05997655913233757,
        "word_count": 0.05020919442176819,
        "adj_ratio": 0.037352077662944794,
        "punctuation_ratio": 0.030064446851611137,
        "avg_PE": 0.028049694374203682,
        "char_count": 0.02667323127388954
      }
    },
    {
      "sample_id": 1928,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.1946640014648438,
        "FSR": 1.8852020502090454,
        "LPA_Profile_grand_mean": 0.10034492611885071,
        "avg_PE": 0.09670597314834595,
        "flesch_reading_ease": 0.052393004298210144,
        "adj_ratio": 0.039303362369537354,
        "avg_word_length": -0.038973625749349594,
        "punctuation_ratio": 0.03700784593820572,
        "positive_word_ratio": 0.03515572100877762,
        "word_count": 0.034347839653491974
      }
    },
    {
      "sample_id": 356,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.8865861892700195,
        "BIS": 1.8088443279266357,
        "LPA_Profile_grand_mean": 0.2164287567138672,
        "avg_word_length": -0.08501195162534714,
        "char_count": 0.0585482232272625,
        "punctuation_ratio": 0.05297445133328438,
        "avg_PE": -0.047644633799791336,
        "adj_ratio": 0.044936563819646835,
        "adv_ratio": 0.04476320371031761,
        "verb_ratio": 0.04022333770990372
      }
    },
    {
      "sample_id": 1724,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.823367953300476,
        "BIS": 1.8121330738067627,
        "adj_ratio": -0.11555146425962448,
        "LPA_Profile_grand_mean": -0.10994788259267807,
        "positive_word_ratio": -0.07943791896104813,
        "avg_word_length": 0.0582861602306366,
        "verb_ratio": 0.05806543678045273,
        "flesch_reading_ease": 0.05763894319534302,
        "punctuation_ratio": -0.04901660978794098,
        "avg_sentence_length": 0.02664833329617977
      }
    },
    {
      "sample_id": 1700,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.0588796138763428,
        "BIS": -0.7659774422645569,
        "avg_sentence_length": -0.16872058808803558,
        "avg_word_length": -0.13874934613704681,
        "LPA_Profile_grand_mean": -0.08840805292129517,
        "adj_ratio": 0.0827326625585556,
        "flesch_reading_ease": -0.06312179565429688,
        "Fruits and vegetables_sentiment": -0.0609017051756382,
        "positive_word_count": 0.05845029652118683,
        "lexical_diversity": 0.050527848303318024
      }
    },
    {
      "sample_id": 1488,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.8308368921279907,
        "BIS": 1.7712808847427368,
        "LPA_Profile_grand_mean": 0.1540488749742508,
        "avg_PE": 0.11700904369354248,
        "avg_word_length": -0.10924884676933289,
        "punctuation_ratio": -0.07459394633769989,
        "adj_ratio": 0.050205111503601074,
        "positive_word_ratio": 0.04439318925142288,
        "char_count": 0.037051551043987274,
        "negative_word_ratio": -0.03443913906812668
      }
    },
    {
      "sample_id": 685,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.0698498487472534,
        "BIS": 0.24747399985790253,
        "avg_word_length": -0.12158365547657013,
        "adj_ratio": 0.07685255259275436,
        "flesch_reading_ease": -0.07095462083816528,
        "LPA_Profile_grand_mean": -0.06463997066020966,
        "negative_word_ratio": 0.05728686600923538,
        "sports_sentiment": -0.048213858157396317,
        "arts and crafts_mentioned": -0.04653831198811531,
        "positive_word_ratio": 0.042966604232788086
      }
    },
    {
      "sample_id": 899,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.8144108057022095,
        "BIS": 0.5531231164932251,
        "LPA_Profile_grand_mean": 0.17617656290531158,
        "positive_word_ratio": -0.1517350822687149,
        "avg_word_length": -0.13189229369163513,
        "char_count": 0.09623797982931137,
        "Fruits and vegetables_sentiment": -0.08424883335828781,
        "positive_word_count": -0.050825148820877075,
        "adj_ratio": 0.04153827950358391,
        "punctuation_ratio": -0.03968368470668793
      }
    },
    {
      "sample_id": 331,
      "true_label": 1,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -1.1313858032226562,
        "FSR": -0.7116774916648865,
        "adv_ratio": 0.11556170880794525,
        "LPA_Profile_grand_mean": -0.11550907790660858,
        "verb_ratio": 0.10231586545705795,
        "adj_ratio": 0.09326357394456863,
        "positive_word_ratio": -0.058763258159160614,
        "char_count": -0.04652561619877815,
        "avg_sentence_length": 0.03968420997262001,
        "healthy savory food_sentiment": 0.03023533523082733
      }
    },
    {
      "sample_id": 213,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -2.0402214527130127,
        "FSR": -1.95363187789917,
        "adj_ratio": -0.19872377812862396,
        "LPA_Profile_grand_mean": -0.13606299459934235,
        "avg_PE": -0.053960517048835754,
        "flesch_reading_ease": 0.053121812641620636,
        "char_count": -0.0455784909427166,
        "avg_sentence_length": 0.03996218368411064,
        "flesch_kincaid_grade": 0.028656944632530212,
        "sentiment_subjectivity": -0.02565832808613777
      }
    },
    {
      "sample_id": 1953,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.4029300212860107,
        "FSR": 1.9443919658660889,
        "LPA_Profile_grand_mean": -0.10954346507787704,
        "avg_word_length": -0.0506364181637764,
        "punctuation_ratio": 0.04501860588788986,
        "adj_ratio": 0.044144343584775925,
        "char_count": -0.04028841108083725,
        "sentiment_subjectivity": 0.036243923008441925,
        "adv_ratio": 0.027721058577299118,
        "flesch_reading_ease": -0.025860734283924103
      }
    },
    {
      "sample_id": 1515,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.913845419883728,
        "BIS": 0.7839664816856384,
        "avg_word_length": 0.1399354785680771,
        "adj_ratio": 0.09333299100399017,
        "avg_sentence_length": -0.06713464111089706,
        "sentiment_polarity": -0.06425134837627411,
        "LPA_Profile_grand_mean": -0.06072045862674713,
        "punctuation_ratio": 0.056786589324474335,
        "positive_word_count": -0.05061668902635574,
        "negative_word_ratio": -0.04443782940506935
      }
    },
    {
      "sample_id": 1105,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.300664186477661,
        "FSR": 1.9136672019958496,
        "adj_ratio": -0.18386438488960266,
        "LPA_Profile_grand_mean": 0.10264145582914352,
        "avg_PE": 0.07044440507888794,
        "char_count": 0.05545194819569588,
        "negative_word_ratio": -0.04652361944317818,
        "punctuation_ratio": 0.04316120594739914,
        "flesch_reading_ease": -0.03215944766998291,
        "word_count": 0.030909545719623566
      }
    },
    {
      "sample_id": 1972,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3718066215515137,
        "FSR": 1.9823302030563354,
        "LPA_Profile_grand_mean": -0.09798955172300339,
        "avg_word_length": -0.052129972726106644,
        "adj_ratio": 0.04460335150361061,
        "verb_ratio": 0.037087053060531616,
        "punctuation_ratio": 0.03303951770067215,
        "positive_word_ratio": 0.0325888954102993,
        "avg_sentence_length": 0.02992381528019905,
        "flesch_reading_ease": -0.028485607355833054
      }
    },
    {
      "sample_id": 278,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.4178831577301025,
        "FSR": 1.8805532455444336,
        "noun_ratio": 0.09095807373523712,
        "LPA_Profile_grand_mean": -0.08805447071790695,
        "positive_word_ratio": -0.08400940150022507,
        "avg_PE": 0.04127425700426102,
        "punctuation_ratio": 0.0308900848031044,
        "verb_ratio": 0.030609210953116417,
        "adj_ratio": 0.03043415956199169,
        "arts and crafts_mentioned": -0.02982720546424389
      }
    },
    {
      "sample_id": 901,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -1.9739288091659546,
        "FSR": -1.967684030532837,
        "LPA_Profile_grand_mean": -0.1645820140838623,
        "avg_word_length": -0.07246355712413788,
        "avg_PE": -0.07010950893163681,
        "verb_ratio": 0.07004345953464508,
        "adj_ratio": 0.04770456254482269,
        "flesch_kincaid_grade": -0.039879776537418365,
        "char_count": -0.038432776927948,
        "flesch_reading_ease": -0.03652092441916466
      }
    },
    {
      "sample_id": 373,
      "true_label": 1,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.2600560188293457,
        "BIS": 0.42516130208969116,
        "LPA_Profile_grand_mean": -0.15073935687541962,
        "adj_ratio": -0.12585407495498657,
        "verb_ratio": 0.11305121332406998,
        "flesch_reading_ease": 0.08364485204219818,
        "char_count": 0.07680774480104446,
        "avg_sentence_length": 0.06523174792528152,
        "avg_word_length": 0.05082176998257637,
        "word_count": 0.03256602585315704
      }
    },
    {
      "sample_id": 1301,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.4043710231781006,
        "FSR": 2.0623555183410645,
        "LPA_Profile_grand_mean": 0.13945792615413666,
        "adj_ratio": -0.09572272002696991,
        "avg_sentence_length": -0.08505110442638397,
        "avg_word_length": -0.06516344845294952,
        "verb_ratio": -0.049342527985572815,
        "flesch_reading_ease": -0.04879579320549965,
        "char_count": -0.03474557772278786,
        "positive_word_ratio": 0.029223395511507988
      }
    },
    {
      "sample_id": 1859,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3918473720550537,
        "FSR": 1.9001920223236084,
        "adj_ratio": -0.1366416960954666,
        "LPA_Profile_grand_mean": -0.07603979110717773,
        "flesch_reading_ease": 0.06368297338485718,
        "negative_word_ratio": -0.04280886799097061,
        "avg_sentence_length": 0.02695946954190731,
        "verb_ratio": -0.02541067823767662,
        "positive_word_count": -0.021555032581090927,
        "char_count": -0.020431222394108772
      }
    },
    {
      "sample_id": 493,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -0.8044313788414001,
        "LPA_Profile_grand_mean": 0.2198786735534668,
        "positive_word_ratio": -0.17178867757320404,
        "BIS": 0.15284833312034607,
        "avg_word_length": -0.11807745695114136,
        "verb_ratio": 0.09957677870988846,
        "adj_ratio": 0.05439557880163193,
        "punctuation_ratio": -0.03633635863661766,
        "positive_word_count": -0.03452901914715767,
        "avg_sentence_length": 0.033589184284210205
      }
    },
    {
      "sample_id": 1855,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.9763175249099731,
        "BIS": -1.279005527496338,
        "char_count": -0.13111378252506256,
        "avg_PE": 0.10381732881069183,
        "avg_sentence_length": -0.09244180470705032,
        "LPA_Profile_grand_mean": -0.08535434305667877,
        "Fruits and vegetables_sentiment": -0.07922534644603729,
        "sweets_sentiment": 0.0714876800775528,
        "positive_word_count": -0.06834269315004349,
        "word_count": -0.05772760882973671
      }
    },
    {
      "sample_id": 272,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.2704787254333496,
        "FSR": 1.9860436916351318,
        "char_count": -0.08285782486200333,
        "adj_ratio": 0.07934604585170746,
        "avg_word_length": 0.06243037432432175,
        "positive_word_count": -0.046578239649534225,
        "flesch_reading_ease": 0.04525339603424072,
        "word_count": -0.04471325874328613,
        "lexical_diversity": 0.04022524133324623,
        "LPA_Profile_grand_mean": -0.04013606533408165
      }
    },
    {
      "sample_id": 1162,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.356982469558716,
        "FSR": 1.9907985925674438,
        "LPA_Profile_grand_mean": -0.09575725346803665,
        "avg_word_length": 0.06180420517921448,
        "adj_ratio": 0.05099908262491226,
        "arts and crafts_mentioned": -0.03893275931477547,
        "punctuation_ratio": 0.0323142372071743,
        "char_count": 0.029670661315321922,
        "flesch_reading_ease": -0.025717055425047874,
        "positive_word_count": 0.023490142077207565
      }
    },
    {
      "sample_id": 2006,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.2250828742980957,
        "FSR": 1.7579008340835571,
        "LPA_Profile_grand_mean": 0.11828842759132385,
        "sentiment_subjectivity": -0.07279156148433685,
        "sentiment_polarity": 0.052863046526908875,
        "word_count": 0.042589813470840454,
        "avg_sentence_length": 0.038992274552583694,
        "avg_word_length": 0.034893978387117386,
        "lexical_diversity": -0.03184851258993149,
        "adj_ratio": -0.02835758402943611
      }
    },
    {
      "sample_id": 1889,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3932266235351562,
        "FSR": 1.8592075109481812,
        "char_count": 0.11801766604185104,
        "LPA_Profile_grand_mean": -0.09678122401237488,
        "avg_PE": 0.0898943692445755,
        "positive_word_ratio": -0.07715000212192535,
        "avg_word_length": 0.06566224992275238,
        "Fruits and vegetables_sentiment": -0.05054579675197601,
        "adj_ratio": 0.04768814146518707,
        "connector_ratio": 0.0433492586016655
      }
    },
    {
      "sample_id": 1989,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.395932912826538,
        "FSR": 1.8534051179885864,
        "LPA_Profile_grand_mean": -0.06753408908843994,
        "avg_word_length": 0.06555420905351639,
        "adj_ratio": 0.054596252739429474,
        "cohesiveness_score": 0.05350535362958908,
        "negative_word_ratio": -0.05172812193632126,
        "Fruits and vegetables_sentiment": -0.041844774037599564,
        "positive_word_count": -0.03759615868330002,
        "punctuation_ratio": -0.03593534231185913
      }
    },
    {
      "sample_id": 657,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -1.9778223037719727,
        "FSR": -1.9744923114776611,
        "adj_ratio": -0.1348932832479477,
        "LPA_Profile_grand_mean": -0.1170269250869751,
        "cohesiveness_score": 0.08769898861646652,
        "avg_word_length": -0.08011827617883682,
        "flesch_reading_ease": -0.06208929792046547,
        "char_count": -0.044793833047151566,
        "verb_ratio": -0.043469201773405075,
        "avg_PE": -0.040296293795108795
      }
    },
    {
      "sample_id": 566,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.333968162536621,
        "FSR": 1.906312108039856,
        "LPA_Profile_grand_mean": -0.10219442844390869,
        "avg_word_length": 0.09286525845527649,
        "adj_ratio": 0.049797333776950836,
        "positive_word_ratio": -0.040790166705846786,
        "punctuation_ratio": 0.040002286434173584,
        "avg_sentence_length": 0.029027501121163368,
        "verb_ratio": 0.028150565922260284,
        "char_count": 0.028123848140239716
      }
    },
    {
      "sample_id": 881,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -2.152769088745117,
        "BIS": -2.0454156398773193,
        "LPA_Profile_grand_mean": 0.14774726331233978,
        "char_count": -0.06298722326755524,
        "adj_ratio": 0.047152429819107056,
        "sentiment_polarity": -0.04163843393325806,
        "flesch_reading_ease": 0.03790392726659775,
        "word_count": -0.033698491752147675,
        "positive_word_count": 0.025945274159312248,
        "negative_word_ratio": -0.02557835355401039
      }
    },
    {
      "sample_id": 85,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3383517265319824,
        "FSR": 1.9328142404556274,
        "LPA_Profile_grand_mean": 0.12980441749095917,
        "avg_PE": 0.11119868606328964,
        "adj_ratio": 0.04422177001833916,
        "avg_word_length": 0.04273710772395134,
        "char_count": 0.03564838692545891,
        "avg_sentence_length": 0.0321216881275177,
        "Fruits and vegetables_sentiment": -0.029931530356407166,
        "arts and crafts_mentioned": -0.02982720546424389
      }
    },
    {
      "sample_id": 1495,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.2467570304870605,
        "FSR": 1.7269967794418335,
        "LPA_Profile_grand_mean": 0.13025334477424622,
        "avg_PE": 0.10376673191785812,
        "sentiment_subjectivity": -0.08006369322538376,
        "word_count": 0.04468024894595146,
        "flesch_kincaid_grade": -0.042838435620069504,
        "adj_ratio": 0.04151972010731697,
        "positive_word_ratio": 0.02964119054377079,
        "avg_sentence_length": 0.024175502359867096
      }
    },
    {
      "sample_id": 1756,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.9028806686401367,
        "BIS": 0.16251584887504578,
        "LPA_Profile_grand_mean": 0.14139436185359955,
        "avg_word_length": 0.13072851300239563,
        "positive_word_ratio": 0.12223652005195618,
        "char_count": -0.09892117232084274,
        "flesch_reading_ease": 0.08155819028615952,
        "lexical_diversity": 0.08135882019996643,
        "positive_word_count": 0.058461740612983704,
        "word_count": -0.058184921741485596
      }
    },
    {
      "sample_id": 283,
      "true_label": 1,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -0.5676063895225525,
        "avg_word_length": 0.1669643372297287,
        "flesch_reading_ease": -0.10688140988349915,
        "adj_ratio": 0.10665033757686615,
        "Fruits and vegetables_sentiment": -0.09411051869392395,
        "LPA_Profile_grand_mean": -0.09233064204454422,
        "positive_word_count": -0.07721276581287384,
        "avg_PE": 0.05728587880730629,
        "verb_ratio": 0.037794630974531174,
        "FSR": 0.034752778708934784
      }
    },
    {
      "sample_id": 468,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.1485936641693115,
        "FSR": 1.9619228839874268,
        "LPA_Profile_grand_mean": 0.1141846626996994,
        "avg_word_length": -0.09596722573041916,
        "char_count": -0.09257519245147705,
        "word_count": -0.08664707839488983,
        "cohesiveness_score": 0.07255864888429642,
        "avg_PE": -0.06608925014734268,
        "adj_ratio": 0.04870929569005966,
        "flesch_reading_ease": 0.04602627828717232
      }
    },
    {
      "sample_id": 774,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.830830454826355,
        "BIS": 1.808876395225525,
        "LPA_Profile_grand_mean": 0.10820086300373077,
        "avg_word_length": -0.10493741929531097,
        "char_count": 0.10479407012462616,
        "adj_ratio": 0.049631886184215546,
        "positive_word_ratio": 0.04399624466896057,
        "punctuation_ratio": 0.04356633126735687,
        "negative_word_count": 0.035334262996912,
        "flesch_kincaid_grade": -0.03461374714970589
      }
    },
    {
      "sample_id": 354,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -2.1599109172821045,
        "FSR": -2.154036521911621,
        "LPA_Profile_grand_mean": 0.14909926056861877,
        "char_count": -0.06957614421844482,
        "avg_sentence_length": -0.05042877420783043,
        "arts and crafts_mentioned": -0.050137750804424286,
        "adj_ratio": 0.04380375146865845,
        "verb_ratio": -0.039805587381124496,
        "avg_PE": -0.03786676004528999,
        "avg_word_length": 0.03660798445343971
      }
    },
    {
      "sample_id": 368,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.9340260028839111,
        "BIS": -1.7896103858947754,
        "avg_sentence_length": -0.09992203861474991,
        "avg_word_length": 0.09804701805114746,
        "positive_word_ratio": -0.09760162979364395,
        "LPA_Profile_grand_mean": 0.097593754529953,
        "adj_ratio": 0.07322458922863007,
        "char_count": -0.056745320558547974,
        "word_count": -0.055117782205343246,
        "connector_ratio": -0.05387955904006958
      }
    },
    {
      "sample_id": 1906,
      "true_label": 0,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.094799518585205,
        "FSR": -1.3262563943862915,
        "avg_word_length": -0.1289907991886139,
        "avg_PE": -0.12393013387918472,
        "LPA_Profile_grand_mean": -0.10330194979906082,
        "cohesiveness_score": 0.04963225871324539,
        "avg_sentence_length": 0.04632817581295967,
        "noun_ratio": -0.04616313427686691,
        "positive_word_ratio": 0.04315357655286789,
        "flesch_reading_ease": 0.03802650421857834
      }
    },
    {
      "sample_id": 695,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.9371088743209839,
        "BIS": 0.3522019386291504,
        "LPA_Profile_grand_mean": 0.09567956626415253,
        "positive_word_ratio": 0.08919129520654678,
        "avg_sentence_length": -0.08745989203453064,
        "avg_word_length": 0.07233719527721405,
        "positive_word_count": 0.06517128646373749,
        "flesch_reading_ease": 0.04679332673549652,
        "char_count": -0.03952183201909065,
        "adj_ratio": -0.03682004287838936
      }
    },
    {
      "sample_id": 534,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.389728546142578,
        "FSR": 1.9045252799987793,
        "LPA_Profile_grand_mean": -0.12056615203619003,
        "positive_word_ratio": -0.08252990245819092,
        "avg_word_length": -0.06123889237642288,
        "punctuation_ratio": 0.04865662381052971,
        "noun_ratio": -0.03885192051529884,
        "adj_ratio": 0.03749262914061546,
        "avg_PE": -0.03459572046995163,
        "flesch_kincaid_grade": -0.02785898931324482
      }
    },
    {
      "sample_id": 1588,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.331455707550049,
        "FSR": 1.988680124282837,
        "LPA_Profile_grand_mean": 0.1250676065683365,
        "positive_word_ratio": -0.08008180558681488,
        "adj_ratio": 0.03969317302107811,
        "char_count": 0.034256696701049805,
        "verb_ratio": -0.02924320101737976,
        "shortness_score": 0.026195518672466278,
        "punctuation_ratio": 0.025074027478694916,
        "food_sentiment": -0.023278433829545975
      }
    },
    {
      "sample_id": 1101,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.9967907667160034,
        "BIS": -1.982226848602295,
        "LPA_Profile_grand_mean": -0.11411059647798538,
        "avg_word_length": -0.09590591490268707,
        "sweets_sentiment": 0.07511692494153976,
        "flesch_reading_ease": -0.03942292928695679,
        "adj_ratio": 0.03818993270397186,
        "sentiment_polarity": -0.03115921840071678,
        "avg_sentence_length": 0.018836572766304016,
        "positive_word_count": 0.018192876130342484
      }
    },
    {
      "sample_id": 512,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -0.5292122960090637,
        "FSR": 0.2842065989971161,
        "LPA_Profile_grand_mean": 0.1956751048564911,
        "avg_sentence_length": -0.17592757940292358,
        "avg_word_length": -0.14299200475215912,
        "avg_PE": 0.08488539606332779,
        "flesch_reading_ease": -0.07669799774885178,
        "positive_word_count": -0.0620105117559433,
        "verb_ratio": -0.05867554247379303,
        "word_count": -0.04676017537713051
      }
    },
    {
      "sample_id": 148,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.9652934074401855,
        "BIS": 1.3820558786392212,
        "avg_word_length": 0.1529703438282013,
        "LPA_Profile_grand_mean": 0.12170517444610596,
        "adj_ratio": 0.09186509996652603,
        "lexical_diversity": 0.0694345235824585,
        "flesch_reading_ease": 0.06251687556505203,
        "punctuation_ratio": 0.05255107954144478,
        "avg_sentence_length": -0.04658880457282066,
        "sentiment_polarity": -0.04502948373556137
      }
    },
    {
      "sample_id": 1851,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.4020285606384277,
        "FSR": 1.8876519203186035,
        "LPA_Profile_grand_mean": -0.1242724061012268,
        "punctuation_ratio": -0.0806884616613388,
        "Fruits and vegetables_sentiment": -0.033791784197092056,
        "adj_ratio": 0.0308515727519989,
        "food_sentiment": -0.029946591705083847,
        "avg_word_length": -0.02757105603814125,
        "flesch_kincaid_grade": -0.026759294793009758,
        "positive_word_count": 0.023775223642587662
      }
    },
    {
      "sample_id": 76,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.8580098152160645,
        "BIS": 1.2523986101150513,
        "LPA_Profile_grand_mean": 0.179322749376297,
        "avg_word_length": -0.12685315310955048,
        "punctuation_ratio": -0.1091444194316864,
        "flesch_reading_ease": 0.04732361063361168,
        "adj_ratio": 0.04517531767487526,
        "word_count": 0.04394065588712692,
        "sentiment_subjectivity": 0.03986232727766037,
        "lexical_diversity": -0.029855603352189064
      }
    },
    {
      "sample_id": 1422,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.299309015274048,
        "FSR": 1.8437979221343994,
        "LPA_Profile_grand_mean": -0.09861699491739273,
        "positive_word_ratio": -0.06624674797058105,
        "punctuation_ratio": -0.06490686535835266,
        "char_count": 0.046378154307603836,
        "avg_word_length": -0.04265417158603668,
        "adj_ratio": 0.03514827415347099,
        "flesch_kincaid_grade": 0.034641094505786896,
        "flesch_reading_ease": 0.031288452446460724
      }
    },
    {
      "sample_id": 1379,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3210599422454834,
        "FSR": 1.8459004163742065,
        "adj_ratio": 0.07230627536773682,
        "punctuation_ratio": -0.0714961513876915,
        "LPA_Profile_grand_mean": -0.06018846482038498,
        "flesch_reading_ease": 0.04394417256116867,
        "sentiment_subjectivity": 0.04066343605518341,
        "positive_word_ratio": 0.035650625824928284,
        "flesch_kincaid_grade": 0.03213522583246231,
        "negative_word_ratio": -0.028669528663158417
      }
    },
    {
      "sample_id": 1293,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.295652389526367,
        "FSR": 1.9959946870803833,
        "char_count": -0.094519704580307,
        "LPA_Profile_grand_mean": 0.08637452125549316,
        "adj_ratio": 0.07079210132360458,
        "word_count": -0.06844568252563477,
        "avg_word_length": 0.06563018262386322,
        "avg_PE": -0.05031596124172211,
        "positive_word_count": -0.048670925199985504,
        "shortness_score": -0.0410502590239048
      }
    },
    {
      "sample_id": 427,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3830151557922363,
        "FSR": 1.8753066062927246,
        "avg_PE": 0.12229389697313309,
        "LPA_Profile_grand_mean": 0.08986520022153854,
        "punctuation_ratio": -0.08570018410682678,
        "char_count": -0.07923514395952225,
        "avg_word_length": -0.07575452327728271,
        "word_count": -0.07503342628479004,
        "sports_sentiment": -0.03907789662480354,
        "Fruits and vegetables_sentiment": -0.0383630134165287
      }
    },
    {
      "sample_id": 1440,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -1.9478545188903809,
        "FSR": -1.080371618270874,
        "LPA_Profile_grand_mean": 0.17018704116344452,
        "adj_ratio": 0.09104002267122269,
        "avg_word_length": -0.07337171584367752,
        "verb_ratio": -0.045508868992328644,
        "avg_PE": 0.03581530600786209,
        "sentiment_polarity": -0.02704339101910591,
        "shortness_score": 0.026909753680229187,
        "avg_sentence_length": 0.026601262390613556
      }
    },
    {
      "sample_id": 1873,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 2.0248024463653564,
        "BIS": 1.2657221555709839,
        "adj_ratio": -0.16050897538661957,
        "LPA_Profile_grand_mean": -0.1359267681837082,
        "avg_word_length": -0.09318849444389343,
        "punctuation_ratio": 0.04786737635731697,
        "avg_PE": -0.038443367928266525,
        "flesch_reading_ease": -0.03587150573730469,
        "positive_word_ratio": 0.03200795501470566,
        "flesch_kincaid_grade": -0.027637440711259842
      }
    },
    {
      "sample_id": 686,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.915029764175415,
        "BIS": -1.452950119972229,
        "char_count": 0.19561395049095154,
        "LPA_Profile_grand_mean": -0.10352310538291931,
        "avg_word_length": -0.0766201987862587,
        "cohesiveness_score": 0.050594888627529144,
        "word_count": 0.05005815252661705,
        "avg_sentence_length": 0.04218336567282677,
        "flesch_kincaid_grade": -0.042176056653261185,
        "flesch_reading_ease": 0.03988393396139145
      }
    },
    {
      "sample_id": 1413,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.7249374389648438,
        "punctuation_ratio": -0.17827284336090088,
        "avg_word_length": 0.16590231657028198,
        "LPA_Profile_grand_mean": 0.10863238573074341,
        "adj_ratio": 0.10097072273492813,
        "flesch_reading_ease": 0.07619111239910126,
        "positive_word_count": -0.060351815074682236,
        "avg_PE": -0.053668003529310226,
        "flesch_kincaid_grade": 0.04527219384908676,
        "BIS": -0.02856731228530407
      }
    },
    {
      "sample_id": 918,
      "true_label": 0,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 1.6142327785491943,
        "adj_ratio": -0.21059094369411469,
        "LPA_Profile_grand_mean": -0.09352903068065643,
        "avg_sentence_length": -0.0901101753115654,
        "Fruits and vegetables_sentiment": -0.07854725420475006,
        "positive_word_count": -0.07431931048631668,
        "sentiment_subjectivity": -0.07365120202302933,
        "sentiment_polarity": 0.06930342316627502,
        "BIS": 0.0681227594614029,
        "punctuation_ratio": 0.05772591754794121
      }
    },
    {
      "sample_id": 1954,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3714582920074463,
        "FSR": 1.8843361139297485,
        "LPA_Profile_grand_mean": -0.09164636582136154,
        "noun_ratio": 0.0780988335609436,
        "positive_word_ratio": -0.043166402727365494,
        "char_count": 0.04275108128786087,
        "avg_sentence_length": 0.032762911170721054,
        "punctuation_ratio": 0.03185100480914116,
        "word_count": 0.03020000457763672,
        "adj_ratio": 0.028908049687743187
      }
    },
    {
      "sample_id": 1490,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -1.892794132232666,
        "adj_ratio": -0.2922564148902893,
        "FSR": 0.2532321810722351,
        "LPA_Profile_grand_mean": -0.13062381744384766,
        "char_count": 0.0830552875995636,
        "avg_PE": -0.0672340914607048,
        "flesch_reading_ease": 0.06597663462162018,
        "sentiment_subjectivity": -0.045143790543079376,
        "avg_sentence_length": 0.04504904896020889,
        "positive_attributes": -0.04442267119884491
      }
    },
    {
      "sample_id": 208,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.5800052881240845,
        "BIS": -1.5786755084991455,
        "cohesiveness_score": 0.09895788878202438,
        "adj_ratio": 0.07749520242214203,
        "LPA_Profile_grand_mean": -0.07714150846004486,
        "sentiment_polarity": -0.06044010818004608,
        "avg_word_length": 0.047428570687770844,
        "positive_word_count": -0.04512349143624306,
        "connector_ratio": -0.03967094048857689,
        "char_count": -0.03225239738821983
      }
    },
    {
      "sample_id": 919,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -2.077874183654785,
        "FSR": -1.9451628923416138,
        "LPA_Profile_grand_mean": 0.18144887685775757,
        "adj_ratio": -0.1283959597349167,
        "sentiment_polarity": -0.06506888568401337,
        "avg_word_length": -0.054515283554792404,
        "avg_PE": -0.051394931972026825,
        "flesch_reading_ease": -0.04154156148433685,
        "avg_sentence_length": 0.025845523923635483,
        "sentiment_subjectivity": -0.02533773146569729
      }
    },
    {
      "sample_id": 464,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.8026716709136963,
        "BIS": -1.4295790195465088,
        "char_count": 0.2124522477388382,
        "adj_ratio": -0.13335998356342316,
        "LPA_Profile_grand_mean": -0.104314424097538,
        "avg_word_length": 0.09309414774179459,
        "flesch_reading_ease": 0.08911442756652832,
        "noun_ratio": -0.07612910866737366,
        "word_count": 0.0689820945262909,
        "sentiment_subjectivity": -0.0631004050374031
      }
    },
    {
      "sample_id": 538,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "FSR": 2.0224714279174805,
        "BIS": 1.3223732709884644,
        "adj_ratio": 0.08256588876247406,
        "LPA_Profile_grand_mean": -0.061516642570495605,
        "sentiment_subjectivity": -0.06055881083011627,
        "flesch_reading_ease": -0.05894569680094719,
        "punctuation_ratio": 0.05428808182477951,
        "char_count": -0.04902062192559242,
        "avg_word_length": -0.04547198861837387,
        "sentiment_polarity": -0.0447753444314003
      }
    },
    {
      "sample_id": 337,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "BIS": -1.9837443828582764,
        "FSR": -1.6845282316207886,
        "LPA_Profile_grand_mean": -0.14645874500274658,
        "positive_word_ratio": -0.06459064036607742,
        "adj_ratio": 0.04690161347389221,
        "char_count": -0.03843670338392258,
        "avg_PE": 0.038388729095458984,
        "flesch_reading_ease": -0.03649759665131569,
        "avg_sentence_length": 0.0318320170044899,
        "sentiment_polarity": -0.02829667180776596
      }
    },
    {
      "sample_id": 79,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.210601329803467,
        "FSR": 1.9345676898956299,
        "LPA_Profile_grand_mean": -0.07942501455545425,
        "avg_word_length": -0.05401305854320526,
        "flesch_reading_ease": 0.04834550619125366,
        "positive_word_ratio": 0.04108763486146927,
        "adj_ratio": 0.03910942003130913,
        "punctuation_ratio": 0.036054275929927826,
        "noun_ratio": -0.035194773226976395,
        "char_count": 0.03131355717778206
      }
    },
    {
      "sample_id": 300,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "BIS": 2.3927595615386963,
        "FSR": 1.9404826164245605,
        "LPA_Profile_grand_mean": -0.060764070600271225,
        "adj_ratio": 0.05305846035480499,
        "char_count": -0.04651167243719101,
        "punctuation_ratio": -0.043306123465299606,
        "avg_PE": -0.03629967197775841,
        "flesch_reading_ease": -0.03002420999109745,
        "positive_word_ratio": 0.02939181588590145,
        "shortness_score": -0.02836965210735798
      }
    },
    {
      "sample_id": 365,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -1.9069048166275024,
        "BIS": -0.7400952577590942,
        "LPA_Profile_grand_mean": 0.21825748682022095,
        "char_count": -0.13475722074508667,
        "positive_word_ratio": -0.1178659126162529,
        "avg_word_length": -0.08830753713846207,
        "word_count": -0.08494158089160919,
        "Fruits and vegetables_sentiment": -0.08192773908376694,
        "positive_word_count": -0.0718497708439827,
        "adj_ratio": 0.057204876095056534
      }
    },
    {
      "sample_id": 585,
      "true_label": 1,
      "predicted_label": 1,
      "top_contributing_features": {
        "flesch_reading_ease": 0.29661259055137634,
        "FSR": -0.21761037409305573,
        "BIS": 0.18420682847499847,
        "adj_ratio": -0.1834210455417633,
        "avg_word_length": -0.14933572709560394,
        "positive_word_ratio": 0.12510284781455994,
        "LPA_Profile_grand_mean": -0.07814683020114899,
        "positive_word_count": 0.07746909558773041,
        "lexical_diversity": 0.07184717804193497,
        "noun_ratio": -0.04953685402870178
      }
    },
    {
      "sample_id": 2112,
      "true_label": 0,
      "predicted_label": 0,
      "top_contributing_features": {
        "FSR": -2.1082310676574707,
        "BIS": -2.0583834648132324,
        "LPA_Profile_grand_mean": -0.12153702229261398,
        "avg_word_length": 0.10251852124929428,
        "avg_PE": 0.06360539048910141,
        "char_count": -0.060002002865076065,
        "adj_ratio": 0.04923568293452263,
        "Fruits and vegetables_sentiment": -0.045138027518987656,
        "sentiment_polarity": -0.02797843888401985,
        "avg_sentence_length": -0.025785202160477638
      }
    }
  ]
}